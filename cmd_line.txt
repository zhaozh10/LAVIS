Installation:
1) conda create -n lavis python=3.10 -y
2) pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117
3) pip install -r requirements.txt
4) Due to internet connection, please download bert-base-uncased on your local machine and upload it to YOUR_HOME/.cache/huggingface/hub/
5) Also, download https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_vitL.pth  and upload it to YOUR_HOME/.cache/torch/hub/checkpoints/



Implementation:
The "sbatch" command has an issue with DistributedDataParallel (DDP) not functioning correctly on our bme slurm cluster. Please use the second command instead.
BLIP-2 stage 1:
1) sbatch run_scripts/blip2/train/bme_stage1_pmc.sh lavis/projects/blip2/train/pretrain_stage1_pmc.yaml
2) GPUS=4 GPUS_PER_NODE=4 CPUS_PER_TASK=2 run_scripts/blip2/train/slurm_stage1_pmc.sh bme_gpu blip2_stage1 lavis/projects/blip2/train/pretrain_stage1_pmc.yaml